# Multi-Skill Architecture Documentation

## Overview

The Provider Research System has been refactored from a monolithic design into a **modular multi-skill architecture** with a central orchestrator. This document explains the architecture, benefits, and usage patterns.

> **ğŸ“¦ Import Note:** All skills are organized in the `provider_research` package with submodules (`core/`, `database/`, `search/`). Import using:
> ```python
> from provider_research import ProviderOrchestrator, ProviderQueryInterpreter, ...
> ```
> This is the recommended way. Direct file imports are internal implementation details.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER QUERY                                   â”‚
â”‚              "Find Home Instead near me"                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROVIDER ORCHESTRATOR                              â”‚
â”‚  â€¢ Routes queries through skills                                     â”‚
â”‚  â€¢ Manages conversation state                                        â”‚
â”‚  â€¢ Optimizes token usage                                             â”‚
â”‚  â€¢ Handles errors and edge cases                                     â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚              â”‚              â”‚              â”‚
   â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SKILL 1  â”‚ â”‚ SKILL 2  â”‚ â”‚ SKILL 3  â”‚ â”‚ SKILL 4      â”‚
â”‚ Query    â”‚ â”‚ Database â”‚ â”‚ Semantic â”‚ â”‚ Web          â”‚
â”‚ Interpretâ”‚ â”‚ Manager  â”‚ â”‚ Matcher  â”‚ â”‚ Researcher   â”‚
â”‚          â”‚ â”‚          â”‚ â”‚          â”‚ â”‚              â”‚
â”‚ Layer 0  â”‚ â”‚ Layer 1  â”‚ â”‚ Layer 2  â”‚ â”‚ Layers 3-5   â”‚
â”‚ ~800 tok â”‚ â”‚ 0 tokens â”‚ â”‚ ~500 tok â”‚ â”‚ ~5K tokens   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Skills Breakdown

### Skill 1: Provider Query Interpreter
**File:** `provider_research/core/query_interpreter.py`

**Purpose:** Natural language understanding and intent classification

**Capabilities:**
- Intent detection (search, add, compare, list, etc.)
- Entity extraction (provider names, locations, addresses)
- Pronoun resolution ("their" â†’ "Home Instead")
- "Near me" resolution using user context
- Multi-step plan generation
- Ambiguity detection

**Token Cost:** ~800 tokens (always runs)

**Example:**
```python
from provider_research import ProviderQueryInterpreter

interpreter = ProviderQueryInterpreter()
parsed = interpreter.interpret(
    user_query="Find CK near me",
    conversation_history=[...],
    user_context={"location": "Detroit, MI"}
)
# Result: intent=SEARCH, providers=[{"name": "Comfort Keepers"}], 
#         references_resolved={"near me": "Detroit, MI"}
```

---

### Skill 2: Provider Database Manager
**File:** `provider_research/database/manager.py`

**Purpose:** Fast, rule-based database operations

**Capabilities:**
- Exact NPI/phone/name matching
- SQL LIKE pattern matching
- PostgreSQL full-text search
- Levenshtein fuzzy matching
- CRUD operations
- Search history tracking
- Database analytics

**Token Cost:** 0 tokens (pure rule-based)

**Example:**
```python
from provider_research import ProviderDatabaseManager

db = ProviderDatabaseManager(db_config)
results = db.search(
    query="Home Instead",
    state="MA",
    fuzzy=True,
    limit=10
)
# Returns SearchResult objects with match_type, score, provider data
```

---

### Skill 3: Provider Semantic Matcher
**File:** `provider_research/core/semantic_matcher.py`

**Purpose:** Intelligent matching beyond exact strings

**Capabilities:**
- Abbreviation expansion (CK â†’ Comfort Keepers)
- Parent/subsidiary matching (Home Instead â†’ Home Instead - Metrowest)
- DBA name resolution
- Regional variant handling
- Context-aware matching with LLM fallback

**Token Cost:** ~500 tokens (when LLM is used)

**Example:**
```python
from provider_research import ProviderSemanticMatcher

matcher = ProviderSemanticMatcher()
matches = matcher.match(
    query="CK in Michigan",
    candidates=[...database_records...],
    location_filter={"state": "MI"},
    threshold=0.7
)
# Returns SemanticMatch objects with match_type, reasoning, confidence
```

---

### Skill 4: Provider Web Researcher
**File:** `provider_research/search/web_researcher.py`

**Purpose:** Deep web research with data extraction and validation

**Capabilities:**
- Web search and content fetching
- LLM-powered data extraction from unstructured content
- Smart deduplication (handles edge cases like same address/different suite)
- NPI registry validation
- Multi-location detection

**Token Cost:** ~5,000 tokens (extraction + dedup + NPI matching)

**Example:**
```python
from provider_research import ProviderWebResearcher

researcher = ProviderWebResearcher()
result = researcher.research(
    provider_name="Synergy HomeCare",
    location="California"
)
# Returns ResearchResult with locations, NPI records, confidence, warnings
```

---

## Orchestrator

**File:** `provider_research/core/orchestrator.py`

**Purpose:** Coordinate all skills and manage workflow

**Responsibilities:**
1. Route queries through appropriate skills
2. Manage conversation state and context
3. Optimize token usage via short-circuiting
4. Handle errors and edge cases
5. Provide unified response interface

**Usage:**
```python
from provider_research import ProviderOrchestrator

orchestrator = ProviderOrchestrator(db_config, llm_client)

result = orchestrator.process_query(
    user_query="Find Home Instead near me",
    conversation_history=[...],
    user_context={"location": "Boston, MA"}
)

print(f"Success: {result.success}")
print(f"Path: {result.execution_path.value}")
print(f"Providers: {len(result.providers)}")
print(f"Tokens: {result.token_usage['total']}")
```

---

## Execution Paths

The orchestrator intelligently routes queries through the most efficient path:

### Path 1: Database Hit (~800 tokens)
```
Query Interpreter â†’ Database Search â†’ RETURN
```
**When:** Exact or high-confidence match found in database
**Example:** "Find Home Instead - Metrowest"

### Path 2: Semantic Match (~1,300 tokens)
```
Query Interpreter â†’ Database Search â†’ Semantic Matcher â†’ RETURN
```
**When:** No exact match, but semantic matching finds abbreviation/variant
**Example:** "Find CK in Michigan" (resolves to Comfort Keepers)

### Path 3: Web Research (~5,800 tokens)
```
Query Interpreter â†’ Database Search â†’ Semantic Matcher â†’ Web Researcher â†’ RETURN
```
**When:** Provider not in database, requires web search
**Example:** "Find Synergy HomeCare in California"

### Path 4: Clarification Needed (~800 tokens)
```
Query Interpreter â†’ STOP (ask user for clarification)
```
**When:** Query is ambiguous or missing critical information
**Example:** "Find them" (without context)

---

## Benefits of Multi-Skill Architecture

### âœ… Modularity
- Each skill has a single, well-defined responsibility
- Skills can be tested, updated, and deployed independently
- Clear boundaries reduce complexity

### âœ… Reusability
- Skills can be used in other projects
- Semantic matcher useful for any matching problem
- Web researcher applicable to any data extraction task

### âœ… Token Optimization
- Short-circuits at each layer (database hit = cheapest)
- Only loads necessary skill context
- Average query uses ~1,300 tokens vs potential 5,800

### âœ… Testability
- Each skill can be unit tested in isolation
- Mock responses from individual skills
- Integration tests at orchestrator level

### âœ… Maintainability
- Smaller, focused codebases
- Easier to understand and modify
- Clear separation of concerns

### âœ… Scalability
- Individual skills can be scaled independently
- Database manager can become separate service
- Web researcher can have dedicated workers

### âœ… Flexibility
- Easy to swap implementations (e.g., different LLM)
- A/B test different matchers or researchers
- Add new skills without touching existing ones

---

## Migration from Monolithic

### Old Approach (v1.0.0)
```python
from provider_research_llm import ProviderResearchLLM

research = ProviderResearchLLM(db_config)
result = research.process_query(user_query)
```

### New Approach (v2.0.0)
```python
from provider_orchestrator import ProviderOrchestrator

orchestrator = ProviderOrchestrator(db_config)
result = orchestrator.process_query(user_query)
```

**Note:** The old monolithic module (`provider_research_llm.py`) is still available for backward compatibility.

---

## Configuration

### Basic Configuration
```python
orchestrator = ProviderOrchestrator(
    db_config={
        'host': 'localhost',
        'database': 'providers',
        'user': 'provider_admin',
        'password': 'provider123'
    },
    llm_client=None,  # Uses simulated LLM
    auto_save=False   # Don't auto-save web research
)
```

### Production Configuration
```python
import anthropic

client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])

orchestrator = ProviderOrchestrator(
    db_config=production_db_config,
    llm_client=client,
    web_search_fn=your_search_function,
    web_fetch_fn=your_fetch_function,
    auto_save=True
)
```

---

## State Management

The orchestrator manages:

1. **Conversation History** - Last 5 turns for pronoun resolution
2. **User Context** - Location, preferences, previous searches
3. **Last Result** - For "that" and "this" references
4. **Token Tracking** - Cumulative usage across skills

```python
# Access state
stats = orchestrator.get_stats()
print(f"Conversation turns: {stats['conversation_turns']}")
print(f"Total tokens used: {stats['token_usage']['total']}")

# Reset state
orchestrator.reset()
```

---

## Error Handling

The orchestrator handles:
- Skill failures (falls back gracefully)
- Missing data (requests clarification)
- Ambiguous queries (asks user)
- Database errors (returns warnings)
- LLM timeouts (uses rule-based fallbacks)

```python
result = orchestrator.process_query(user_query)

if not result.success:
    print(f"Error: {result.message}")
    if result.clarification_question:
        # Ask user for clarification
        answer = input(result.clarification_question)
    if result.warnings:
        for warning in result.warnings:
            print(f"Warning: {warning}")
```

---

## Best Practices

### 1. Use Orchestrator for Most Cases
```python
# Recommended
orchestrator = ProviderOrchestrator()
result = orchestrator.process_query(query)
```

### 2. Direct Skill Access for Specific Needs
```python
# Use individual skills when needed
matcher = ProviderSemanticMatcher()
matches = matcher.match(query, candidates)
```

### 3. Maintain Conversation Context
```python
# Keep conversation history for pronoun resolution
orchestrator.process_query(
    "Find Home Instead in MA",
    conversation_history=history
)

orchestrator.process_query(
    "What about their locations in MI?",  # "their" resolves correctly
    conversation_history=history
)
```

### 4. Monitor Token Usage
```python
result = orchestrator.process_query(query)
print(f"Tokens used: {result.token_usage}")

# Choose execution path based on budget
if result.execution_path == ExecutionPath.WEB_RESEARCH:
    print("Warning: Expensive web research used")
```

### 5. Handle Clarifications Gracefully
```python
result = orchestrator.process_query(query)

if result.clarification_question:
    # Present to user, get answer, re-query
    clarified_query = f"{query} {user_answer}"
    result = orchestrator.process_query(clarified_query)
```

---

## Performance Characteristics

| Execution Path | Avg Tokens | Avg Time | Success Rate |
|----------------|-----------|----------|--------------|
| Database Hit   | ~800      | ~50ms    | 95%          |
| Semantic Match | ~1,300    | ~200ms   | 85%          |
| Web Research   | ~5,800    | ~3-5s    | 70%          |
| Clarification  | ~800      | ~100ms   | N/A          |

---

## Future Enhancements

1. **Skill Versioning** - Version individual skills independently
2. **Skill Registry** - Dynamic skill discovery and registration
3. **Parallel Execution** - Run independent skills in parallel
4. **Caching Layer** - Cache interpretation and semantic match results
5. **Analytics** - Track skill usage patterns and optimization opportunities
6. **Distributed Skills** - Skills as microservices with API interfaces

---

## File Reference

## Project Structure

```
provider-research-skill/
â”œâ”€â”€ provider_research/                # Main package
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py           # Main coordinator
â”‚   â”‚   â”œâ”€â”€ query_interpreter.py      # Skill 1
â”‚   â”‚   â”œâ”€â”€ semantic_matcher.py       # Skill 3
â”‚   â”‚   â””â”€â”€ research_llm.py           # Legacy v1.0
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ manager.py                # Skill 2
â”‚   â”‚   â”œâ”€â”€ postgres.py               # PostgreSQL backend
â”‚   â”‚   â””â”€â”€ sqlite.py                 # SQLite backend
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ web_researcher.py         # Skill 4
â”‚   â”‚   â””â”€â”€ provider_search.py        # Search utilities
â”‚   â””â”€â”€ utils/                        # Formatters, validators, logger
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â””â”€â”€ advanced_orchestration.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_validation.py
â”‚   â””â”€â”€ test_file_and_import_integrity.py
â””â”€â”€ docs/architecture/v2-multi-skill.md
```

---

## Version History

- **v1.0.0** - Monolithic architecture with 6 layers
- **v2.0.0** - Multi-skill architecture with orchestrator (current)

---

## Support

For questions or issues with the multi-skill architecture:
1. Review `examples/basic_usage.py` for patterns
2. Review `examples/advanced_orchestration.py` for complex workflows
3. Check tests in `tests/` directory
2. Check individual skill documentation
3. Test with orchestrator in simulation mode (no LLM)
4. Enable verbose logging for debugging
