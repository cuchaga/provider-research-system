# Provider Research Skill - Quick Reference

## ğŸš€ QUICK START FOR NEW CHAT

**Last Updated:** February 9, 2026 (Evening - Latest)  
**Latest Commit:** 2de6f7e  
**Status:** âœ… All tests passing, documentation fully synchronized

### Upload These Files:
1. **`PROJECT_CONTEXT.md`** - Complete project state & architecture
2. **`SESSION_HANDOFF.md`** - What just happened (recent work)
3. **`QUICK_REFERENCE.md`** - This file (quick commands)

### Then Say:
"Let's continue working on the provider research system. I've uploaded the context files."

**Or if you have the zip:**
1. Upload `provider-research-skill.zip`
2. Say: "Extract the zip and review the latest changes"

---

## ğŸ“ PROJECT STRUCTURE (v2.0.0)

```
provider-research-skill/
â”œâ”€â”€ v2.0.0 Multi-Skill Architecture
â”‚   â”œâ”€â”€ provider_research/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py           # Main coordinator (22KB, 618 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ query_interpreter.py      # Skill 1: NLU (12KB, 354 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_matcher.py       # Skill 3: Matching (12KB, 327 lines)
â”‚   â”‚   â”‚   â””â”€â”€ research_llm.py           # Legacy v1.0 (32KB)
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py                # Skill 2: DB Ops (22KB, 680 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres.py               # PostgreSQL backend
â”‚   â”‚   â”‚   â””â”€â”€ sqlite.py                 # SQLite backend
â”‚   â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”‚   â”œâ”€â”€ web_researcher.py         # Skill 4: Research (23KB, 710 lines)
â”‚   â”‚   â”‚   â””â”€â”€ provider_search.py        # Search utilities
â”‚   â”‚   â””â”€â”€ utils/                        # Validators, formatters, logger
â”‚   â”œâ”€â”€ examples/
â”‚   â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â”‚   â””â”€â”€ advanced_orchestration.py
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_validation.py
â”‚       â””â”€â”€ test_file_and_import_integrity.py
â”‚
â”œâ”€â”€ v1.0.0 Legacy (Still Supported)
â”‚   â”œâ”€â”€ provider_research_llm.py          # Monolithic (32KB)
â”‚   â”œâ”€â”€ provider_database_postgres.py     # Database (23KB)
â”‚   â”œâ”€â”€ provider_search.py                # Search (5.5KB)
â”‚   â””â”€â”€ test_provider_research_llm.py     # Tests (45KB)
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ README.md                         # Package documentation
â”‚   â”œâ”€â”€ docs/architecture/                # Architecture docs
â”‚   â”‚   â”œâ”€â”€ overview.md                   # Technical architecture
â”‚   â”‚   â”œâ”€â”€ v2-multi-skill.md             # v2.0.0 multi-skill architecture
â”‚   â”‚   â””â”€â”€ project-structure.md          # Directory layout
â”‚   â””â”€â”€ docs/getting-started.md           # Quick start guide
â”‚
â””â”€â”€ Config
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ setup.py
    â””â”€â”€ scripts/init_database.sh
```

---

## ğŸ—ï¸ ARCHITECTURE AT A GLANCE (v2.0.0)

```
User Query
    â†“
[ORCHESTRATOR] Coordinates all skills
    â†“
[Skill 1] Query Interpreter    ~800 tokens   â† Always runs
    â†“
[Skill 2] Database Manager      0 tokens      â† Can STOP here âœ“
    â†“
[Skill 3] Semantic Matcher      ~500 tokens   â† Can STOP here âœ“
    â†“
[Skill 4] Web Researcher        ~5000 tokens
    â†“
Results
```

**Execution Paths:**
1. **DB Hit** (~800 tok, ~50ms) - Found in database
2. **Semantic** (~1,300 tok, ~200ms) - Matched via abbreviation/parent
3. **Web Research** (~5,800 tok, ~3-5s) - Deep research needed
4. **Clarification** (~800 tok, <100ms) - Ambiguous query

--v2.0.0 Multi-Skill Tests: 6/6 Passing**
- âœ… Skill imports
- âœ… Component initialization  
- âœ… Query interpretation
- âœ… Semantic matching
- âœ… Web researcher functions
- âœ… Orchestrator structure

**v1.0.0 Legacy Tests: 22/22

## âœ… TEST STATUS

**22/22 Tests Passing**
 (v2.0.0)

### Orchestrator Benefits
- **Modularity**: 4 independent skills vs monolith
- **Token Optimization**: Short-circuits at each layer
- **State Management**: Conversation context & pronoun resolution
- **Error Handling**: Graceful fallbacks & clarifications
- **Backward Compatible**: v1.0.0 code still works

### Understands Natural Language
- "Find Home Instead near me" â†’ uses user's location
- "What about their locations?" â†’ resolves "their" from context
- "Add that to the database" â†’ knows what "that" refers to

### Smart Matching
- "CK" â†’ Comfort Keepers (abbreviation)
- "Home Instead" â†’ finds all subsidiaries
- Won't force matches that don't exist

### Intelligent Deduplication
- Same phone = duplicate
- Same address, diff suite = duplicate
- Franchise vs HQ = NOT duplicate

---

## ğŸ’» COMMON COMMANDS

### v2.0.0 Usage (Recommended)
```python
# Initialize orchestrator
from provider_research_skill import ProviderOrchestrator

orchestrator = ProviderOrchestrator(db_config)
result = orchestrator.process_query(
    user_query="Find Home Instead near me",
    user_context={"location": "Boston, MA"}
)

print(f"Path: {result.execution_path.value}")
print(f"Tokens: {result.token_usage['total']}")
print(f"Providers: {len(result.providers)}")
```

### v1.0.0 Usage (Still Supported)
```python
from provider_research_skill import ProviderResearchLLM

research = ProviderResearchLLM(db_config)
result = research.process_query(user_query)
```

### Run Tests
```bash
# Quick validation tests (v2.0.0)
pytest tests/test_validation.py -v

# Comprehensive tests
pytest tests/ -v --cov=provider_research

# Examples
python3 examples/basic_usage.py
python3 examples/advanced_orchestration.py
```

### Intelligent Deduplication
- Same phone = duplicate
- Same address, diff suite = duplicate
- Franchise vs HQ = NOT duplicate

---

## ğŸ’» COMMON COMMANDS

```bash
# Run tests
python3 test_provider_research_llm.py

# Start database
sudo service postgresql start

# Initialize database
bash scripts/init_database.sh

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“Š DATABASE INFO

**Connection:**
```
Host: localhost
Port: 5432
Database: providers
User: provider_admin
Password: provider123
```

**Test Data:** 8 providers (Home Instead, Comfort Keepers, Visiting Angels, BrightStar, GCP REIT)

---

## ğŸ¯ QUICK CODE REFERENCE

### Process a Query
```python
from provider_research_llm import ProviderResearchLLM
from provider_database_postgres import ProviderDatabasePostgres

db = ProviderDatabasePostgres()
research = ProviderResearchLLM(db=db)
result = research.process_query("Find Home Instead in MA")
```

### Just Interpret (Layer 0)
```python
parsed = research.interpret_query("Find CK near me", 
    user_context={"location": "Detroit, MI"})
```

### Just Semantic Match (Layer 2)
```python
matches = research.semantic_match("Comfort Keepers", {"state": "MI"})
```

---

## ğŸ”® FUTURE IDEAS

- [ ] Embedding model for faster semantic search
- [ ] Batch processing for multiple providers
- [ ] Learning from user corrections
- [ ] Rate limiting for external APIs
- [ ] Caching layer for repeated queries

---

## ğŸ“ NOTES FOR CLAUDE

When continuing this project:
1. The test suite uses simulated LLM responses (no API key needed)
2. Database must be running for tests to pass
3. All 6 layers are implemented and working
4. The project is GitHub-ready with full documentation
