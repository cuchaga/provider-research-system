# Provider Research System - Multi-Skill Architecture (v2.0.0)

## ğŸ¯ Overview

A modular provider research system with **4 specialized skills** coordinated by a central **orchestrator**. Optimized for intelligence, efficiency, and maintainability.

### What Changed in v2.0.0?

**Before (v1.0.0):**
- Single monolithic module with 6 tightly-coupled layers
- ~32KB single file
- Hard to test, modify, or reuse components

**After (v2.0.0):**
- 4 independent skills + orchestrator
- Each skill ~300-600 lines, focused on single responsibility
- Easy to test, extend, and reuse
- **Backward compatible** - v1.0.0 code still works!

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROVIDER ORCHESTRATOR                        â”‚
â”‚  Routes queries â†’ Manages state â†’ Optimizes tokens             â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚            â”‚            â”‚            â”‚
   â–¼            â–¼            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚SKILL 1 â”‚  â”‚SKILL 2 â”‚  â”‚SKILL 3 â”‚  â”‚SKILL 4     â”‚
â”‚Query   â”‚  â”‚Databaseâ”‚  â”‚Semanticâ”‚  â”‚Web         â”‚
â”‚Interp  â”‚  â”‚Manager â”‚  â”‚Matcher â”‚  â”‚Researcher  â”‚
â”‚~800tok â”‚  â”‚0 tokensâ”‚  â”‚~500tok â”‚  â”‚~5K tokens  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Installation

```bash
cd provider-research-skill
pip install -r requirements.txt
```

### Basic Usage (v2.0.0 - Recommended)

```python
from provider_research_skill import ProviderOrchestrator

# Initialize orchestrator
orchestrator = ProviderOrchestrator(
    db_config={
        'host': 'localhost',
        'database': 'providers',
        'user': 'provider_admin',
        'password': 'provider123'
    }
)

# Process query
result = orchestrator.process_query(
    user_query="Find Home Instead near me",
    user_context={"location": "Boston, MA"}
)

# Results
print(f"Success: {result.success}")
print(f"Execution path: {result.execution_path.value}")
print(f"Providers found: {len(result.providers)}")
print(f"Tokens used: {result.token_usage['total']}")
print(f"Time: {result.execution_time_ms:.1f}ms")
```

### Legacy Usage (v1.0.0 - Still Supported)

```python
from provider_research_skill import ProviderResearchLLM

research = ProviderResearchLLM(db_config)
result = research.process_query("Find Home Instead in MA")
```

---

## ğŸ“¦ The 4 Skills

> **Import Note:** All components are available from the main `provider_research` package:
> ```python
> from provider_research import (
>     ProviderOrchestrator,
>     ProviderQueryInterpreter,
>     ProviderDatabaseManager,
>     ProviderSemanticMatcher,
>     ProviderWebResearcher
> )
> ```

### Skill 1: Provider Query Interpreter
**File:** `provider_research/core/query_interpreter.py`

```python
from provider_research import ProviderQueryInterpreter

interpreter = ProviderQueryInterpreter()
parsed = interpreter.interpret(
    user_query="Find CK near me",
    user_context={"location": "Detroit, MI"}
)
# Returns: ParsedQuery with intent, entities, filters, references
```

**Capabilities:**
- Intent classification (search, add, compare, list)
- Entity extraction (names, locations, addresses)
- Pronoun resolution ("their" â†’ provider name)
- "Near me" handling
- Multi-step planning

**Token Cost:** ~800 tokens

---

### Skill 2: Provider Database Manager
**File:** `provider_research/database/manager.py`

```python
from provider_research import ProviderDatabaseManager

db = ProviderDatabaseManager(db_config)
results = db.search(
    query="Home Instead",
    state="MA",
    fuzzy=True
)
# Returns: SearchResult objects with match scores
```

**Capabilities:**
- Exact NPI/phone/name matching
- PostgreSQL full-text search
- Levenshtein fuzzy matching
- CRUD operations
- Database analytics

**Token Cost:** 0 tokens (pure rule-based)

---

### Skill 3: Provider Semantic Matcher
**File:** `provider_research/core/semantic_matcher.py`

```python
from provider_research import ProviderSemanticMatcher

matcher = ProviderSemanticMatcher()
matches = matcher.match(
    query="CK",
    candidates=[...database_records...],
    threshold=0.7
)
# Returns: SemanticMatch objects with reasoning
```

**Capabilities:**
- Abbreviation expansion (CK â†’ Comfort Keepers)
- Parent/subsidiary matching
- DBA name resolution
- Context-aware matching

**Token Cost:** ~500 tokens (with LLM), 0 tokens (rule-based fallback)

---

### Skill 4: Provider Web Researcher
**File:** `provider_research/search/web_researcher.py`

```python
from provider_web_researcher import ProviderWebResearcher

researcher = ProviderWebResearcher()
result = researcher.research(
    provider_name="Synergy HomeCare",
    location="California"
)
# Returns: ResearchResult with locations, NPIs, confidence
```

**Capabilities:**
- Web search and extraction
- LLM-powered data extraction
- Smart deduplication
- NPI registry validation

**Token Cost:** ~5,000 tokens (extraction + dedup + NPI)

---

## ğŸ¬ Execution Paths

The orchestrator automatically chooses the most efficient path:

### Path 1: Database Hit (Cheapest - ~800 tokens)
```
Interpreter â†’ Database â†’ RETURN
```
**When:** "Find Home Instead - Metrowest"

### Path 2: Semantic Match (~1,300 tokens)
```
Interpreter â†’ Database â†’ Semantic Matcher â†’ RETURN
```
**When:** "Find CK in Michigan" (expands to Comfort Keepers)

### Path 3: Web Research (~5,800 tokens)
```
Interpreter â†’ Database â†’ Matcher â†’ Web Researcher â†’ RETURN
```
**When:** "Find Synergy HomeCare" (not in database)

### Path 4: Clarification (~800 tokens)
```
Interpreter â†’ STOP (ask user)
```
**When:** "Find them" (ambiguous query)

---

## ğŸ“Š Examples

See [`examples/`](provider-research-skill/examples/) for complete examples:

```bash
cd provider-research-skill
python3 examples/basic_usage.py
python3 examples/advanced_orchestration.py
```

**Examples include:**
1. Basic search workflow
2. Multi-turn conversation with pronoun resolution
3. Different execution paths demonstration
4. Custom workflow configurations
5. Multi-step query handling

---

## ğŸ§ª Testing

### Quick Test
```bash
cd provider-research-skill
pytest tests/test_validation.py -v
```

**Tests:**
- âœ… Package imports
- âœ… Component initialization
- âœ… Query interpretation
- âœ… Database operations
- âœ… Semantic matching
- âœ… Configuration management

### Comprehensive Test Suite
```bash
pytest tests/ -v --cov=provider_research
```
22/22 tests for LLM-enhanced features

---

## ğŸ“ Project Structure

```
provider-research-system/
â”œâ”€â”€ PROJECT_CONTEXT.md                # Project context for new sessions
â”œâ”€â”€ QUICK_REFERENCE.md                # Quick reference guide
â”œâ”€â”€ SESSION_HANDOFF.md                # Session handoff notes
â”œâ”€â”€ provider-research-skill/
â”‚   â”œâ”€â”€ provider_research/               # Main package
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py          # Main coordinator (22KB, 618 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ query_interpreter.py     # Skill 1 (12KB, 354 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_matcher.py      # Skill 3 (12KB, 327 lines)
â”‚   â”‚   â”‚   â””â”€â”€ research_llm.py          # Legacy v1.0 (32KB)
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py               # Skill 2 (22KB, 680 lines)
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres.py              # PostgreSQL backend
â”‚   â”‚   â”‚   â””â”€â”€ sqlite.py                # SQLite backend
â”‚   â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”‚   â”œâ”€â”€ web_researcher.py        # Skill 4 (23KB, 710 lines)
â”‚   â”‚   â”‚   â””â”€â”€ provider_search.py       # Search utilities
â”‚   â”‚   â””â”€â”€ utils/                       # Utilities
â”‚   â”œâ”€â”€ docs/architecture/v2-multi-skill.md  # Multi-skill architecture
â”‚   â”œâ”€â”€ examples/                        # Usage examples
â”‚   â”œâ”€â”€ tests/                           # Test suite
â”‚   â”œâ”€â”€ provider_search.py                # Fuzzy search
â”‚   â””â”€â”€ test_provider_research_llm.py     # Full test suite
â”‚   â”‚
â”‚   â””â”€â”€ [Documentation]
â”‚      â”œâ”€â”€ README.md
â”‚       â””â”€â”€ docs/
â”‚           â”œâ”€â”€ architecture/
â”‚           â”œâ”€â”€ guides/
â”‚           â””â”€â”€ getting-started.md
```

---

## ğŸ”§ Configuration

### Database Setup
```bash
# Start PostgreSQL
sudo service postgresql start

# Initialize database
cd provider-research-skill/scripts
./init_database.sh
```

### Environment Variables
```bash
export ANTHROPIC_API_KEY="your-api-key"  # Optional for LLM features
```

### Python Configuration
```python
# Production setup
import anthropic

orchestrator = ProviderOrchestrator(
    db_config={
        'host': 'localhost',
        'database': 'providers',
        'user': 'provider_admin',
        'password': 'provider123'
    },
    llm_client=anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY']),
    auto_save=True  # Auto-save web research results
)
```

---

## ğŸ’¡ Best Practices

### 1. Use the Orchestrator
```python
# âœ… Recommended
orchestrator = ProviderOrchestrator()
result = orchestrator.process_query(query)
```

### 2. Maintain Conversation Context
```python
# Enable pronoun resolution
orchestrator.process_query(
    "Find Home Instead in MA",
    conversation_history=[...]
)

orchestrator.process_query(
    "What about their MI locations?",  # "their" resolves to Home Instead
    conversation_history=[...]
)
```

### 3. Monitor Token Usage
```python
result = orchestrator.process_query(query)
if result.token_usage['total'] > 3000:
    print("Warning: Expensive query used web research")
```

### 4. Handle Clarifications
```python
result = orchestrator.process_query(query)
if result.clarification_question:
    answer = input(result.clarification_question)
    result = orchestrator.process_query(f"{query} {answer}")
```

---

## ğŸ¯ Benefits of Multi-Skill Architecture

### âœ… Modularity
Each skill has single responsibility, clear boundaries

### âœ… Testability
Skills tested independently, easier to debug

### âœ… Reusability
Semantic matcher reusable in other matching problems

### âœ… Token Optimization
Short-circuits at each layer:
- DB hit: ~800 tokens
- Semantic: ~1,300 tokens
- Web research: ~5,800 tokens

### âœ… Maintainability
Smaller focused codebases, easier to understand

### âœ… Scalability
Skills can scale independently as microservices

---

## ğŸ“š Documentation

- **[Multi-Skill Architecture](provider-research-skill/docs/architecture/v2-multi-skill.md)** - Complete architecture guide
- **[Architecture Overview](provider-research-skill/docs/architecture/overview.md)** - Technical specifications
- **[Project Structure](provider-research-skill/docs/architecture/project-structure.md)** - Directory layout
- **[Getting Started](provider-research-skill/docs/getting-started.md)** - Installation and setup
- **[PROJECT_CONTEXT.md](PROJECT_CONTEXT.md)** - Project overview and context

---

## ğŸ”„ Migration from v1.0.0

### Option 1: Use New Orchestrator (Recommended)
```python
# Old
from provider_research_skill import ProviderResearchLLM
research = ProviderResearchLLM(db_config)

# New
from provider_research_skill import ProviderOrchestrator
orchestrator = ProviderOrchestrator(db_config)
```

### Option 2: Continue Using Legacy
```python
# Still works!
from provider_research_skill import ProviderResearchLLM
research = ProviderResearchLLM(db_config)
result = research.process_query(query)
```

---

## ğŸ“ˆ Performance

| Execution Path | Avg Tokens | Avg Time | Success Rate |
|----------------|-----------|----------|--------------|
| Database Hit   | ~800      | ~50ms    | 95%          |
| Semantic Match | ~1,300    | ~200ms   | 85%          |
| Web Research   | ~5,800    | ~3-5s    | 70%          |

---

## ğŸ¤ Contributing

When adding features:
1. Identify which skill(s) need updates
2. Update skill independently
3. Test skill in isolation
4. Test orchestrator integration
5. Update documentation

---

## ğŸ“ License

MIT License - see [LICENSE](provider-research-skill/LICENSE)

---

## ğŸ”® Future Enhancements

- [ ] Skill versioning and registry
- [ ] Parallel skill execution
- [ ] Caching layer for interpretations
- [ ] Distributed skills as microservices
- [ ] Real-time analytics dashboard
- [ ] A/B testing framework for skills

---

## ğŸ“ Support

For questions or issues:
1. Review [examples](provider-research-skill/examples/)
2. Check [Multi-Skill Architecture](provider-research-skill/docs/architecture/v2-multi-skill.md)
3. Run tests: `cd provider-research-skill && pytest`

---

**Version:** 2.0.0 - Multi-Skill Architecture  
**Status:** âœ… Production Ready  
**Last Updated:** February 9, 2026
